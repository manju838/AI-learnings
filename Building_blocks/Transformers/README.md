## Transformers

* Transformers are neural networks that can transform data from one sequence to another. (eg. language translation transforms sequence of french words to a sequence of  english words).
* It is a form of semi-supervised learning where models are initially trained using unsupervised learning on large corpus of data and subsequently using supervised learning on targeted labelled data for the corresponding downstream tasks.
* Transformers originated in 2017 in the paper [Attention is all you need](https://arxiv.org/abs/1706.03762). The readme section [here](./ATTENTION_PAPER.md) will give a more details about attention and other conceptual ideas described in the paper.

The below section describes the conceptualisation of transformer as a whole:

